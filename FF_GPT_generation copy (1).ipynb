{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(15000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 15 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Configuration\n",
    "openai.api_key = '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'\n",
    "input_file = \"remainder_to_score.csv\"\n",
    "output_file = \"remainder_scored.csv\"\n",
    "temperature_setting = 0.1\n",
    "max_tokens_setting = 1000\n",
    "\n",
    "# Read the csv sheet into a pandas DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Create a list to store the parsed descriptions\n",
    "parsed_descriptions = []\n",
    "\n",
    "# Your instruction\n",
    "instruction = \"\"\"\n",
    "Your goal is to parse, categorize, and score the valence of the following description.\n",
    "First, parse the description into discrete meaningful chunks. A chunk is defined as a unique occurrence, observation, or thought, typically expressed as a grammatical unit such as a verb phrase, clause, adjective, proper noun, or separated by a conjunction such as for, and, nor, but, or, yet, so.\n",
    "When parsing, if a sentence or phrase appears to belong to multiple categories, split it into the respective distinct chunks. For example, if \"Today I went to the endocrinologist.\" can be categorized as both \"Event\" and \"Time\", split it into \"Today\" as \"Time\" and \"I went to the endocrinologist\" as \"Event\".\n",
    "Then, categorize each chunk of the description as Event, Time, Place, Perceptual, Thought/Emotion, Semantic, Extraneous, or Reflection. Each chunk can be assigned to only one category:\n",
    "Event: Happenings, individuals present, actions or reactions of self and others, topics of conversation.\n",
    "Time: Year, season, month, day of week, time of day, statements about relative timing within an event.\n",
    "Place: Localization of an event including the city, street, building, room, part of room.\n",
    "Perceptual: Auditory, olfactory, tactile, taste, visual and visual details, body position, duration, weather.\n",
    "Thought/Emotion: Emotional state, thoughts, implications of self and others.\n",
    "Semantic: General knowledge or facts and pieces of information that are not directly related to the main experience being described.\n",
    "Extraneous: Tangential events to the main memory recalled.\n",
    "Reflection: Meta-cognitive statements, editorializing, speculation.\n",
    "\n",
    "After categorizing, score the valence of each chunk as (positive), (negative), or (neutral). Valence captures the emotional tone of the chunk, indicating whether it is positive, negative, or neutral in nature. Items are only positive or negative in nature if they have desriptive adjectives in them.\n",
    "Please format your response in the following manner:\n",
    "For chunks:\n",
    "-\"Chunk of text\"\n",
    "-\"Another chunk of text\"\n",
    "...\n",
    "For categories:\n",
    "-Category\n",
    "-Another Category\n",
    "...\n",
    "For valence:\n",
    "-valence\n",
    "-valence\n",
    "\"\"\"\n",
    "\n",
    "def process_description(description):\n",
    "    print(f\"Processing: '{description}'\")\n",
    "    \n",
    "    messages_payload = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": instruction\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": description\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Make the API call\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-0613\",\n",
    "            messages=messages_payload,\n",
    "            temperature=temperature_setting,\n",
    "            max_tokens=max_tokens_setting\n",
    "        )\n",
    "\n",
    "        # Extract and return the output from the response\n",
    "        output = response['choices'][0]['message']['content'].strip()\n",
    "        print(f\"Processed successfully. Output: '{output}'\")\n",
    "        return output\n",
    "\n",
    "    except Exception as e:\n",
    "        error_str = str(e)\n",
    "        if 'Rate limit reached' in error_str:\n",
    "            print(\"Rate limit reached. Retrying after a brief pause.\")\n",
    "            sleep_time = 10  # Default sleep time of 10 seconds\n",
    "            # Extract retry time if provided in the error message\n",
    "            match = re.search(r\"Please try again in (\\d+)ms\", error_str)\n",
    "            if match:\n",
    "                sleep_time = int(match.group(1)) / 1000.0  # Convert to seconds\n",
    "            time.sleep(sleep_time)\n",
    "            return process_description(description)  # Retry after sleeping\n",
    "        else:\n",
    "            print(f\"Error processing description: {description}. Error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Batch processing\n",
    "for index, description in enumerate(df['Descriptions'], start=1):\n",
    "    print(f\"\\nProcessing description {index} out of {len(df['Descriptions'])}\")\n",
    "    result = process_description(description)\n",
    "    \n",
    "    # If there's a result, format and store it; otherwise, store an error message\n",
    "    if result:\n",
    "        parsed_descriptions.append(result)\n",
    "    else:\n",
    "        parsed_descriptions.append(\"Error in processing this description\")\n",
    "\n",
    "# Add the parsed descriptions back to the DataFrame\n",
    "df['Parsed Descriptions'] = parsed_descriptions\n",
    "\n",
    "# Save the DataFrame back to an Excel sheet\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\nProcessing complete! Results saved to '{output_file}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
